{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавление признаков эстетичности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import color\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "from PIL import Image\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "Определим функции, которые вычисляют метрики эстетичности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CFN(img):\n",
    "    pxls = color.rgb2lab(img[:, :, :3]).reshape([img.shape[0] * img.shape[1], 3])\n",
    "\n",
    "    stda = np.std(pxls[:, 1])\n",
    "    stdb = np.std(pxls[:, 2])\n",
    "\n",
    "    centre = (\n",
    "        np.sum(pxls[:, 1]) / pxls.shape[0],\n",
    "        np.sum(pxls[:, 2]) / pxls.shape[0]\n",
    "    )\n",
    "\n",
    "    return int(np.hypot(stda, stdb) + 0.37 * np.hypot(centre[0], centre[1]))\n",
    "\n",
    "\n",
    "def img_entropy(img):\n",
    "    try:\n",
    "        img = color.rgb2gray(img)\n",
    "    except:\n",
    "        img = color.rgba2gray(img)\n",
    "\n",
    "    return np.mean(entropy(img, disk(5)))\n",
    "\n",
    "\n",
    "def rgb_box_count(img, box_size=2):\n",
    "    R, G, B = (img[:, :, i].flatten() for i in range(3))\n",
    "\n",
    "    boxes = np.full((256 // box_size, 256 // box_size, 256 // box_size), False)\n",
    "\n",
    "    for (r, g, b) in np.array([R, G, B]).T:\n",
    "        boxes[\n",
    "            int(r // box_size),\n",
    "            int(g // box_size),\n",
    "            int(b // box_size)\n",
    "        ] = True\n",
    "\n",
    "    return - np.log(np.sum(boxes)) / np.log(box_size / 256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Главная функция\n",
    "Эту функцию мы применим ко всем строкам нашего датасета, и получим на выход 3 метрики эстетичности, которые будут добавлены к датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def add_aesthetics_metrics(row, src=Path('./../images')):\n",
    "    # TODO: поменяейте здесь ./src на путь до папки, где хранятся ваши картинки\n",
    "    img_path = src / row['image']\n",
    "    img = np.array(Image.open(img_path))\n",
    "\n",
    "    cfn = CFN(img)\n",
    "    entropy = img_entropy(img)\n",
    "    # box_count = rgb_box_count(img)\n",
    "    box_count = 0\n",
    "\n",
    "    return pd.Series([cfn, entropy, box_count], index=['cfn', 'entropy', 'box_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given dataset has shape of: (8832, 2104)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "dataset_path = './christies_auction_clean_embeddings.csv'\n",
    "\n",
    "# Read the dataset we have\n",
    "df = pd.read_csv(dataset_path)\n",
    "print('Given dataset has shape of:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a7a7f5a8794fa4b52c3a083cffc405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=884), Label(value='0 / 884'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/35/tb4whj3x0t18xb6yn70mvqs8cq9clk/T/ipykernel_10206/553822965.py:9: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  entropy = img_entropy(img)\n",
      "/var/folders/35/tb4whj3x0t18xb6yn70mvqs8cq9clk/T/ipykernel_10206/553822965.py:9: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  entropy = img_entropy(img)\n",
      "/var/folders/35/tb4whj3x0t18xb6yn70mvqs8cq9clk/T/ipykernel_10206/553822965.py:9: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  entropy = img_entropy(img)\n",
      "/var/folders/35/tb4whj3x0t18xb6yn70mvqs8cq9clk/T/ipykernel_10206/553822965.py:9: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  entropy = img_entropy(img)\n",
      "/var/folders/35/tb4whj3x0t18xb6yn70mvqs8cq9clk/T/ipykernel_10206/553822965.py:9: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  entropy = img_entropy(img)\n",
      "/var/folders/35/tb4whj3x0t18xb6yn70mvqs8cq9clk/T/ipykernel_10206/553822965.py:9: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  entropy = img_entropy(img)\n",
      "/var/folders/35/tb4whj3x0t18xb6yn70mvqs8cq9clk/T/ipykernel_10206/553822965.py:9: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  entropy = img_entropy(img)\n",
      "/var/folders/35/tb4whj3x0t18xb6yn70mvqs8cq9clk/T/ipykernel_10206/553822965.py:9: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  entropy = img_entropy(img)\n",
      "/var/folders/35/tb4whj3x0t18xb6yn70mvqs8cq9clk/T/ipykernel_10206/553822965.py:9: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  entropy = img_entropy(img)\n",
      "/var/folders/35/tb4whj3x0t18xb6yn70mvqs8cq9clk/T/ipykernel_10206/553822965.py:9: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  entropy = img_entropy(img)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compute aesthetics metrics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcfn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox_count\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd_aesthetics_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAfter processing dataset has shape of:\u001b[39m\u001b[38;5;124m'\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Store results into .csv for Orange use\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandarallel/core.py:428\u001b[0m, in \u001b[0;36mparallelize_with_pipe.<locals>.closure\u001b[0;34m(data, user_defined_function, *user_defined_function_args, **user_defined_function_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m generation \u001b[38;5;241m=\u001b[39m count()\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    426\u001b[0m     (worker_status \u001b[38;5;241m==\u001b[39m WorkerStatus\u001b[38;5;241m.\u001b[39mRunning \u001b[38;5;28;01mfor\u001b[39;00m worker_status \u001b[38;5;129;01min\u001b[39;00m workers_status)\n\u001b[1;32m    427\u001b[0m ):\n\u001b[0;32m--> 428\u001b[0m     message: Tuple[\u001b[38;5;28mint\u001b[39m, WorkerStatus, Any] \u001b[38;5;241m=\u001b[39m \u001b[43mmaster_workers_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     worker_index, worker_status, payload \u001b[38;5;241m=\u001b[39m message\n\u001b[1;32m    430\u001b[0m     workers_status[worker_index] \u001b[38;5;241m=\u001b[39m worker_status\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/managers.py:822\u001b[0m, in \u001b[0;36mBaseProxy._callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    819\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tls\u001b[38;5;241m.\u001b[39mconnection\n\u001b[1;32m    821\u001b[0m conn\u001b[38;5;241m.\u001b[39msend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id, methodname, args, kwds))\n\u001b[0;32m--> 822\u001b[0m kind, result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#RETURN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:249\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 249\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:413\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 413\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:378\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    376\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 378\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    379\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute aesthetics metrics\n",
    "df[['cfn', 'entropy', 'box_count']] = df.parallel_apply(add_aesthetics_metrics, axis=1)\n",
    "print('After processing dataset has shape of:', df.shape)\n",
    "\n",
    "# Store results into .csv for Orange use\n",
    "df.to_csv('./christies_auction_clean_embeddings_aesthetics.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
