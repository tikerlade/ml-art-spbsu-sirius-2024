{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Orange3 Orange3-ImageAnalytics PyQt5 nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Также нужно немного магии. Без нее в Jupyter Notebook'е код не заводится\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подключение к Hugging Face\n",
    "\n",
    "To get started you need to:\n",
    "\n",
    "Register or Login.\n",
    "Get a User Access or API token in your Hugging Face profile settings.\n",
    "You should see a token hf_xxxxx (old tokens are api_XXXXXXXX or api_org_XXXXXXX).\n",
    "\n",
    "If you do not submit your API token when sending requests to the API, you will not be able to run inference on your private models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Код применения Orange кубика `ImageEmbedder` в Python можно найти на [GitHub](https://github.com/biolab/orange3-imageanalytics/blob/master/orangecontrib/imageanalytics/image_embedder.py#L95-L106)\n",
    "* Как подключиться к API Hugging Face (с инструкцией по получению токена) можно найти у них в [документации](https://huggingface.co/docs/api-inference/quicktour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the model which will be used & access to HuggingFace\n",
    "MODEL_NAME = \"playgroundai/playground-v2-1024px-aesthetic\"\n",
    "API_TOKEN = \"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\"\n",
    "\n",
    "API_URL = f\"https://api-inference.huggingface.co/models/{MODEL_NAME}\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from orangecontrib.imageanalytics.image_embedder import ImageEmbedder\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def show_img(image: np.ndarray, prompt=''):\n",
    "    plt.imshow(image)\n",
    "    plt.title(prompt)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_img(img_path: str) -> np.ndarray:\n",
    "    return np.array(Image.open(img_path))\n",
    "\n",
    "\n",
    "def prettify_price(price: float):\n",
    "    return \"${:,.2f}\".format(price)\n",
    "\n",
    "\n",
    "def get_embeddings(img_paths: List[str]):\n",
    "    with ImageEmbedder(model='painters') as emb:\n",
    "        emb.clear_cache()\n",
    "        return emb(img_paths)\n",
    "\n",
    "\n",
    "def get_style_prediction(img_paths: str, class_as_str: bool = False, model_path='./style_classifier.pkcls'):\n",
    "    # Берем эмбеддинги от картинок\n",
    "    emb = get_embeddings(img_paths)\n",
    "\n",
    "    # Загружаем модель и получаем стиль - предсказание обученного классификатора\n",
    "    model = pickle.load(open(model_path, 'rb'))\n",
    "    style_classes = model(emb)\n",
    "\n",
    "    # Можно еще научиться выводить уверенность предсказания (оценки вероятностей)\n",
    "    style_probs = ...\n",
    "\n",
    "    # Переводим классы из чиселок в текстовое представление\n",
    "    if class_as_str:\n",
    "        return [model.domain.class_var.str_val(i) for i in style_classes]\n",
    "    return style_classes\n",
    "\n",
    "\n",
    "def get_price_prediction(img_paths: List[str], model_path='price_predictor.pkcls'):\n",
    "    # Берем эмбеддинги от картинок\n",
    "    emb = get_embeddings(img_paths)\n",
    "\n",
    "    # Загружаем модель и получаем предсказание - log_normalized_price\n",
    "    model = pickle.load(open(model_path, 'rb'))\n",
    "    pred_log_price = model(emb)\n",
    "\n",
    "    # Чтобы получить цену в долларах, а не в попугаях - надо пропотенциировать ее по основанию `e`\n",
    "    return np.e ** pred_log_price\n",
    "\n",
    "\n",
    "def query(prompt):\n",
    "    \"\"\"\n",
    "    Function that queries HuggingFace model with given prompt\n",
    "    \"\"\"\n",
    "    payload = {\"inputs\": prompt}\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "def query_img(prompt):\n",
    "    \"\"\"\n",
    "    Parse image from HuggingFace API answer. \n",
    "    \"\"\"\n",
    "    image_bytes = query(prompt)\n",
    "    return Image.open(io.BytesIO(image_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим как можно пользоваться этой функцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x29c7701d0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Querying model using API call & decode image\u001b[39;00m\n\u001b[1;32m      2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe piece of art in minimalism  style that was sold in 100k$\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mquery_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Show image itself\u001b[39;00m\n\u001b[1;32m      6\u001b[0m show_img(image)\n",
      "Cell \u001b[0;32mIn[25], line 76\u001b[0m, in \u001b[0;36mquery_img\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mParse image from HuggingFace API answer. \u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m image_bytes \u001b[38;5;241m=\u001b[39m query(prompt)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/PIL/Image.py:3280\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3278\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3279\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3280\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x29c7701d0>"
     ]
    }
   ],
   "source": [
    "# Querying model using API call & decode image\n",
    "prompt = \"The piece of art in minimalism  style that was sold in 100k$\"\n",
    "image = query_img(prompt)\n",
    "\n",
    "# Show image itself\n",
    "show_img(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.save('./hf_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.1.3 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './../day4/price_predictor.pkcls'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m image\u001b[38;5;241m.\u001b[39msave(img_path[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m style \u001b[38;5;241m=\u001b[39m get_style_prediction(img_path, class_as_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./../day3/style_classifier.pkcls\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m image_price \u001b[38;5;241m=\u001b[39m \u001b[43mget_price_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./../day4/price_predictor.pkcls\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(style)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(prettify_price(image_price[\u001b[38;5;241m0\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[2], line 55\u001b[0m, in \u001b[0;36mget_price_prediction\u001b[0;34m(img_paths, model_path)\u001b[0m\n\u001b[1;32m     52\u001b[0m emb \u001b[38;5;241m=\u001b[39m get_embeddings(img_paths)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Загружаем модель и получаем предсказание - log_normalized_price\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     56\u001b[0m pred_log_price \u001b[38;5;241m=\u001b[39m model(emb)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Чтобы получить цену в долларах, а не в попугаях - надо пропотенциировать ее по основанию `e`\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './../day4/price_predictor.pkcls'"
     ]
    }
   ],
   "source": [
    "img_path =['./hf_image.jpg']\n",
    "\n",
    "image.save(img_path[0])\n",
    "style = get_style_prediction(img_path, class_as_str=True, model_path='./../day3/style_classifier.pkcls')[0]\n",
    "image_price = get_price_prediction(img_path, model_path='./../day4/price_predictor.pkcls')\n",
    "\n",
    "print(style)\n",
    "print(prettify_price(image_price[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "В prompt подставить 3 разных стиля. Посмотреть по нашему классификатору правильно ли генерируется стиль. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. \n",
    "Попробуйте добавить в промпт все стили сразу, что же он вернет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.\n",
    "Из прошлых занятий мы знаем, что в среднем картины ... стиля продаются дороже ... стиля. \n",
    "Сгенерируйте 5 картин в одном стиле и 5 картин в другом стиле.\n",
    "\n",
    "По нашей модели регрессии предскажите цены для каждой картины и усредните результат по каждому из стилей.\n",
    "Правда ли сгенерированные картины ... стиля все еще дороже сгенерированных картин ... стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4. Style Transfer\n",
    "\n",
    "1. Загрузите фотографию\n",
    "1. Предскажите для нее стиль и цену нашими моделями.\n",
    "1. Выберите модель Image-to-Image и попросите модифицировать эту картину под какой-то стиль\n",
    "1. Проверьте, что теперь наш классификатор определяет стиль картинки как тот, который был указан в промпте\n",
    "1. Увеличилась ли стоимость картины, когда мы ее адаптировали под определенный стиль? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81679015e1f4b91b18e1b041a6943b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52c67eccb8146ac8eb6c99c0c87cef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bbdaf39f2d4857aa114d2be885cb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17204e8044c40d19ce6ad47cba6b25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder_2/config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d7b5c60e6c4033997f12025418bbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89bb9c5c44c400eb22910cf9abc8d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172bc5c3204648b99e1d6f0491bd9366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/config.json:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8f3a93d7054bdd8aa108351e5be38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b24434e7de487896e8bff38f0d88e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5abc5bd8da54a0d91a7d092e61f66a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94ebde25d144539a06c5a2522dbeaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.fp16.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9648708c4a40fcb068ffdb909946b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0670aae15dc040f1800f3a6528b98f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/4.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8833f94043a34f8fbe5e715867e4f5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f464423563741b0a6dd1af3e101e265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "url = \"https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png\"\n",
    "\n",
    "init_image = load_image(url).convert(\"RGB\")\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt, image=init_image).images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5. Генерация самой дорогой картины\n",
    "1. Возьмите сгенерированную картину из прошлого шага\n",
    "1. Напишите промпт, который бы увеличивал ее стоимость.\n",
    "1. Напишите цикл из 10 итераций, где на каждой итерации:\n",
    "    1. Делается 3 вызова Image-to-Image модели\n",
    "    1. Каждая сгенерированная картинка оценивается на стоимость\n",
    "    1. Выбирается та, что самая дорогая по стоимости (или оставляем картину с предыдущего шага)\n",
    "    1. Повторяем итерацию цикла\n",
    "\n",
    "Интересно посмотреть на сколько мы сможем повысить цену такими просьбами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def estimate_price(img):\n",
    "    # TODO: replace this function with the one, written in Day #3\n",
    "    ...\n",
    "    return random.random()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
